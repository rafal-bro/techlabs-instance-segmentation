{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNVnI2nWVPavxOW3ishFH2N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafal-bro/techlabs-instance-segmentation/blob/main/1_data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Data Preprocessing**"
      ],
      "metadata": {
        "id": "zLH8gMEQsKOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "The classical first step in any data science and machine learning project is to collect the necessary data. The [Wild Intelligence Lab (WIL)](https://wildintelligencelab.com) provided us with a small amount of already labeled drone images which are of interest for this project. We added additional image data without labels from the *savmap* dataset, which is publicliy available [here](https://zenodo.org/record/1204408#.YlB2x7hCTfY).\n",
        "The additional images were recorded in the same reserve, are 4000x3000 pixels in size and show small areas of steppe landscape from above. Just like the images provided from WIL.\n",
        "\n",
        "As the goal of this work is to provide accurate detections of landscape features using deep learning techniques, we needed to extend our training dataset by adding labels. This is a manual process, where a polygon around an object is created and afterwards a class is defined. Various applications for this labeling task exist. We chose the `labelme` package which can be easily added to the working environment and envoked using the terminal. A part of the *savmap* dataset was labeled and the remaining images were reserved for inference i.e. model predictions.\n",
        "\n",
        "![](https://drive.google.com/uc?id=1S0u8sbXGtFDBkFZkJpMgTZjOztH-mw2R)\n",
        "\n",
        "       Fig 1:  Annotation process in labelme\n",
        "\n",
        "\n",
        "In Fig. 1, the labeling process is shown. Corresponding to our detection goals, we defined six classes: tree, bush, dead tree, road, aardvark hole, and animal. In the labelme GUI, they are marked with different colours. The so-called masks resulting from the labeling process are then stored in one json-file per image. Once all the instances were labelled, we performed data cleaning and filtering (i.e. exclusion of images without labels) and created a COCO-like datatset using the package `labelme2coco`. \n",
        "\n",
        "**What is COCO Format ?** [COCO (Common Objects in Context)](https://cocodataset.org/#home) is a large image dataset designed for object detection, semantic segmentation, and instance segmentation. A COCO-like dataset is characterized by one file which provides a computer-readable form of the instance shapes and locations for all images in the dataset and a folder containing the image data. The dataset file stores its annotations in the JSON format describing object classes, bounding boxes, and bitmasks. The json file of COCO format has the following structure:\n",
        "\n",
        " ```\n",
        "{\n",
        "\"images\": [\n",
        "\t\t     {\n",
        "\t           \"height\":2400,\n",
        "\t\t      \"width\" : 2400\n",
        "               \"id\": 0,\n",
        "               \"license\": 1,\n",
        "               \"file_name\": \"<filename0>.<ext>\",\n",
        "\t\t      },...\n",
        "\t\t   ],\n",
        "\"annotations\":[{\n",
        "            \"id\": 0,\n",
        "            \"image_id\": 0,\n",
        "            \"category_id\": 2,\n",
        "            \"bbox\": [260, 177, 231, 199],\n",
        "            \"segmentation\": [...],\n",
        "            \"area\": 45969,\n",
        "            \"iscrowd\": 0\n",
        "        },...],\n",
        "\"categories\": [...\n",
        "        {\n",
        "            \"id\": 2,\n",
        "            \"name\": \"tree\",\n",
        "            \"supercategory\": \"tree\"\n",
        "        },...]\n",
        "}\n",
        "```\n",
        "\n",
        "As we annotated images of size 4000x3000 pixels, the whole process of labeling was very time consuming. To ensure equal image size thoughout the whole dataset (the images provided by WIL were of size 2048x2048 pixels) and enable higher batch size during training (lower memory requirement per iteration), we decided to crop each image into smaller parts of size 1024x1024 pixels. Cropping of the previously created COCO-like dataset was done using the `sahi` python package. `sahi` is a vision library used for slicing images and COCO-like datasets into smaller parts [8]. After slicing, the dataset was filtered again and images without labels were removed. \n",
        "\n",
        "Overall, we collected 1680 images of 1024x1024 pixels with labels for model development. Finally, we performed a training-test split in the ratio of 90:10. The test set is excluded from model development and the training set will be used for model training in the next notebook.\n",
        "\n",
        "Below the described steps are implemented."
      ],
      "metadata": {
        "id": "sxivjHsasPbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the Environment"
      ],
      "metadata": {
        "id": "bUhpgfrkPIaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install labelme2coco==0.1.2\n",
        "!pip install sahi\n",
        "!pip install funcy\n",
        "!pip install Pillow==9.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_9kjnBnxN0r",
        "outputId": "3b07ab51-bd97-4209-df53-047f10331387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: labelme2coco==0.1.2 in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from labelme2coco==0.1.2) (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from labelme2coco==0.1.2) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from labelme2coco==0.1.2) (9.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6.0->labelme2coco==0.1.2) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6.0->labelme2coco==0.1.2) (4.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6.0->labelme2coco==0.1.2) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6.0->labelme2coco==0.1.2) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6.0->labelme2coco==0.1.2) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6.0->labelme2coco==0.1.2) (3.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sahi in /usr/local/lib/python3.7/dist-packages (0.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from sahi) (3.13)\n",
            "Requirement already satisfied: pillow>=8.2.0 in /usr/local/lib/python3.7/dist-packages (from sahi) (9.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from sahi) (2.23.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (from sahi) (0.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.2.0.32 in /usr/local/lib/python3.7/dist-packages (from sahi) (4.6.0.66)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from sahi) (1.8.2)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from sahi) (3.1.10)\n",
            "Requirement already satisfied: click==8.0.4 in /usr/local/lib/python3.7/dist-packages (from sahi) (8.0.4)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from sahi) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.4->sahi) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.2.0.32->sahi) (1.21.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->sahi) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire->sahi) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.4->sahi) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.4->sahi) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->sahi) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->sahi) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->sahi) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->sahi) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (1.17)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow==9.0.0 in /usr/local/lib/python3.7/dist-packages (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import modules and mount drive."
      ],
      "metadata": {
        "id": "gRguAN1MvMea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLRdhGyeTqUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be2ad4f-dca8-4e02-f291-647f4ad3ee6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify paths."
      ],
      "metadata": {
        "id": "8B0C6817nJH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify root to kuzikus_group04 folder\n",
        "PROJECT_ROOT = r'/content/drive/MyDrive/techlabs_instance_segmentation'\n",
        "\n",
        "# specify folder containing raw image data as well as images with labelme annotations - should be placed in project 'data' folder\n",
        "RAW_DATA_FOLDER = 'savmap_dataset_labeled'\n",
        "\n",
        "# specify desired folder name for results\n",
        "DATA_FOLDER = 'kuzikus_coco'"
      ],
      "metadata": {
        "id": "cjOfrDd4m0oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set flags."
      ],
      "metadata": {
        "id": "LwzhYvzinLO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if True, images will be cropped\n",
        "CROP_IMGS = True\n",
        "\n",
        "# specify desired image size for crop \n",
        "IMG_SIZE = 1024\n",
        "\n",
        "# if True, inference dataset will be created i.e. images without labels will be prepared for detection\n",
        "CREATE_INFERENCE = True"
      ],
      "metadata": {
        "id": "augVYI6_9hnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specify image settings."
      ],
      "metadata": {
        "id": "aTGlkd3ynZzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify initial image format, make sure that all images have the same extension - resulting images will be jpg for memory reasons\n",
        "IMG_FORMAT = 'png'"
      ],
      "metadata": {
        "id": "3UXVgiSqtUL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# root path of data \n",
        "DATA_ROOT = os.path.join(PROJECT_ROOT, 'data')\n",
        "\n",
        "# path to folder containing helper functions\n",
        "HELPER_DIR = os.path.join(PROJECT_ROOT, 'helper_functions')\n",
        "\n",
        "# import helper functions\n",
        "sys.path.append(HELPER_DIR)\n",
        "import preprocessing as pre"
      ],
      "metadata": {
        "id": "SNS2vHsQniAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_DATA_DIR = os.path.join(DATA_ROOT, RAW_DATA_FOLDER)\n",
        "DATA_DIR = os.path.join(DATA_ROOT, DATA_FOLDER)"
      ],
      "metadata": {
        "id": "UYKFraeo_T5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create COCO-like Datasets"
      ],
      "metadata": {
        "id": "VCUHeLOdrwnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, clean data and create base coco dataset. This might take some time."
      ],
      "metadata": {
        "id": "Q2NCSBU_oFyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre.create_coco(RAW_DATA_DIR, IMG_FORMAT, DATA_DIR)"
      ],
      "metadata": {
        "id": "UPgSigqYoCnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crop images to desired size and save new dataset to folder. New images without any instances will be automatically excluded."
      ],
      "metadata": {
        "id": "ARf4Vzr8qikx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre.crop_images_coco(DATA_DIR, IMG_SIZE)"
      ],
      "metadata": {
        "id": "O4HjQKzmqhbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cf114e-7cfd-498e-d7f7-1d60de9ff916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexing coco dataset annotations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading coco annotations: 100%|██████████| 192/192 [00:01<00:00, 124.80it/s]\n",
            "  2%|▏         | 3/192 [00:01<02:21,  1.33it/s]06/11/2022 01:09:03 - ERROR - shapely.geos -   TopologyException: Input geom 0 is invalid: Self-intersection at 1285.8375655477105 1962.0938106445351\n",
            "06/11/2022 01:09:03 - INFO - shapely.geos -   Self-intersection at or near point 1285.8375655477105 1962.0938106445351\n",
            "06/11/2022 01:09:03 - WARNING - sahi.slicing -   Invalid annotation found, skipping this image: /content/drive/MyDrive/techlabs_instance_segmentation/data/kuzikus_coco/A8-Ortho_30720_55296.png\n",
            " 48%|████▊     | 93/192 [01:09<01:16,  1.30it/s]06/11/2022 01:10:11 - ERROR - shapely.geos -   TopologyException: Input geom 0 is invalid: Self-intersection at 1228.1736975940537 1099.41970398383\n",
            "06/11/2022 01:10:11 - INFO - shapely.geos -   Self-intersection at or near point 1228.1736975940537 1099.41970398383\n",
            "06/11/2022 01:10:11 - WARNING - sahi.slicing -   Invalid annotation found, skipping this image: /content/drive/MyDrive/techlabs_instance_segmentation/data/kuzikus_coco/acbbff7b49c94464932857c68b12cda8.png\n",
            " 70%|███████   | 135/192 [01:38<00:56,  1.02it/s]06/11/2022 01:10:40 - ERROR - shapely.geos -   TopologyException: Input geom 0 is invalid: Self-intersection at 2331.5296523517382 351.61145194274025\n",
            "06/11/2022 01:10:40 - INFO - shapely.geos -   Self-intersection at or near point 2331.5296523517382 351.61145194274025\n",
            "06/11/2022 01:10:40 - WARNING - sahi.slicing -   Invalid annotation found, skipping this image: /content/drive/MyDrive/techlabs_instance_segmentation/data/kuzikus_coco/d9348e34b3ac4411805e282b1f6b8d00.png\n",
            " 91%|█████████ | 175/192 [02:13<00:12,  1.35it/s]06/11/2022 01:11:15 - ERROR - shapely.geos -   TopologyException: Input geom 0 is invalid: Self-intersection at 1670.6599812623615 1132.8573741860114\n",
            "06/11/2022 01:11:15 - INFO - shapely.geos -   Self-intersection at or near point 1670.6599812623615 1132.8573741860114\n",
            "06/11/2022 01:11:15 - WARNING - sahi.slicing -   Invalid annotation found, skipping this image: /content/drive/MyDrive/techlabs_instance_segmentation/data/kuzikus_coco/b0ec7f2c5ea04bf5947d27f5fd69049d.png\n",
            "100%|██████████| 192/192 [02:26<00:00,  1.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1680 entries in /content/drive/MyDrive/techlabs_instance_segmentation/data/kuzikus_coco_1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform training - test split of cropped dataset."
      ],
      "metadata": {
        "id": "yQ7inCicq3ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COCO_FILE_PATH = os.path.join(DATA_DIR+f'_{IMG_SIZE}', f'{DATA_FOLDER}_{IMG_SIZE}.json')"
      ],
      "metadata": {
        "id": "r1n85uCOq_Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% will be training and the remaining 20% test\n",
        "pre.split_coco(COCO_FILE_PATH, split=0.8)"
      ],
      "metadata": {
        "id": "B5HQdrteq23t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crop inference dataset."
      ],
      "metadata": {
        "id": "EKnDmM0FrZnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre.crop_images_inference(DATA_DIR, RAW_DATA_DIR, IMG_SIZE, IMG_FORMAT)"
      ],
      "metadata": {
        "id": "P-_NslWwGakh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a18c5c-a764-4deb-c6f3-31e160c7d321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7993 images saved in /content/drive/MyDrive/techlabs_instance_segmentation/data/kuzikus_coco_1024_inference\n"
          ]
        }
      ]
    }
  ]
}